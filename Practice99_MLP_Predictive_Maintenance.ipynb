{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "title",
   "metadata": {},
   "source": "# Practice 99 — MLP for Predictive Maintenance\n\nPractice 06 (Extra)에서 선형 모델로 풀기 어려웠던 **제조 설비 고장 예측** 문제를\n**다층 퍼셉트론(MLP)**으로 해결합니다.\n\n**AI4I 2020 Predictive Maintenance Dataset** ([UCI #601](https://archive.ics.uci.edu/dataset/601/ai4i+2020+predictive+maintenance+dataset))\n\n| # | Model | Features | Expected Accuracy |\n|---|---|---|---|\n| 1 | Logistic Regression (NumPy) | 2개 (RPM, Torque) | ~75% |\n| 2 | Logistic Regression (NumPy) | 5개 (전체) | ~83% |\n| 3 | MLP (PyTorch) | 5개 (전체) | **~96%** |\n\n> **핵심 메시지:**  \n> 선형 모델 + 소수 변수로는 한계가 있는 산업 데이터에서,  \n> **더 많은 변수 + 비선형 모델(MLP)**이 정확도를 극적으로 향상시킵니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pip-install",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -q ucimlrepo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "imports",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10, 4)\n",
    "plt.rcParams['axes.unicode_minus'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "data-title",
   "metadata": {},
   "source": "---\n# 데이터 로드 — AI4I 2020 Predictive Maintenance\n\n제조 설비의 센서 데이터로 **고장 여부**를 예측하는 이진 분류 문제입니다.\n\n| Feature | 설명 | 단위 |\n|---|---|---|\n| **Air temperature** | 공기 온도 | K |\n| **Process temperature** | 공정 온도 | K |\n| **Rotational speed** | 회전 속도 | rpm |\n| **Torque** | 토크 | Nm |\n| **Tool wear** | 공구 마모도 | min |\n\n> **기계공학과의 관련성:**  \n> 회전 기계의 진동, 온도, 토크 등 센서 데이터로 고장을 사전에 예측하는 것은  \n> **예지 정비(Predictive Maintenance)**의 핵심이며, 스마트 제조의 기반 기술입니다.\n\n### Class Imbalance 문제\n\n원본 데이터는 고장 비율이 ~3.4%로 극도로 불균형합니다.  \n불균형 데이터에서 \"전부 정상\"이라고 예측해도 96.6% 정확도가 나오므로,  \n**균형 샘플링(undersampling)**으로 정상:고장 = 1:1로 맞춥니다."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AI4I 2020 Predictive Maintenance (UCI #601)\n",
    "ai4i = fetch_ucirepo(id=601)\n",
    "X_all = ai4i.data.features\n",
    "y_all = ai4i.data.targets\n",
    "\n",
    "print('=== Raw Data ===')\n",
    "print(f'Features: {X_all.columns.tolist()}')\n",
    "print(f'Targets:  {y_all.columns.tolist()}')\n",
    "print(f'Shape:    {X_all.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "data-prep",
   "metadata": {},
   "outputs": [],
   "source": "# 수치형 5개 feature 추출\nfeature_cols = ['Air temperature', 'Process temperature',\n                'Rotational speed', 'Torque', 'Tool wear']\nX_raw = X_all[feature_cols].values.astype(float)\ny_raw = y_all['Machine failure'].values.astype(int)\n\nprint(f'정상: {(y_raw==0).sum()}, 고장: {(y_raw==1).sum()} ({y_raw.mean():.1%} failure rate)')\n\n# --- 균형 샘플링 (undersampling) ---\nnp.random.seed(42)\nidx_fail = np.where(y_raw == 1)[0]                         # 고장 전체\nidx_normal = np.where(y_raw == 0)[0]\nidx_normal_sub = np.random.choice(idx_normal, len(idx_fail), replace=False)\nidx = np.concatenate([idx_fail, idx_normal_sub])\nnp.random.shuffle(idx)\n\nX_bal = X_raw[idx]\ny_bal = y_raw[idx]\n\nprint(f'\\n=== Balanced Data ===')\nprint(f'정상: {(y_bal==0).sum()}, 고장: {(y_bal==1).sum()}, 총: {len(y_bal)}')"
  },
  {
   "cell_type": "markdown",
   "id": "sec1-title",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Logistic Regression — 2 Features\n",
    "\n",
    "Practice 06에서 사용한 것과 동일한 **NumPy gradient descent** 코드로  \n",
    "**회전 속도(RPM)**와 **토크(Torque)** 2개 변수만 사용합니다.\n",
    "\n",
    "$$\\sigma(z) = \\frac{1}{1+e^{-z}}, \\qquad J = -\\sum_n \\bigl[ y_n \\log \\sigma(z_n) + (1-y_n) \\log(1-\\sigma(z_n)) \\bigr]$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec1-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2 features: RPM + Torque\n",
    "f1_raw = X_bal[:, 2]   # Rotational speed\n",
    "f2_raw = X_bal[:, 3]   # Torque\n",
    "\n",
    "# 표준화\n",
    "f1_mean, f1_std = f1_raw.mean(), f1_raw.std()\n",
    "f2_mean, f2_std = f2_raw.mean(), f2_raw.std()\n",
    "f1 = (f1_raw - f1_mean) / f1_std\n",
    "f2 = (f2_raw - f2_mean) / f2_std\n",
    "\n",
    "X2 = np.column_stack([np.ones(len(y_bal)), f1, f2])\n",
    "\n",
    "sigmoid = lambda z: 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
    "\n",
    "w = np.zeros(3)\n",
    "rho = 0.01\n",
    "n_epochs = 300\n",
    "\n",
    "loss_hist_2f = []\n",
    "for ep in range(n_epochs):\n",
    "    o = sigmoid(X2 @ w)\n",
    "    loss = -np.sum(y_bal * np.log(o+1e-15) + (1-y_bal) * np.log(1-o+1e-15))\n",
    "    loss_hist_2f.append(loss)\n",
    "    grad = X2.T @ (o - y_bal)\n",
    "    w = w - rho * grad\n",
    "\n",
    "pred_2f = (sigmoid(X2 @ w) >= 0.5).astype(int)\n",
    "acc_2f = np.mean(pred_2f == y_bal)\n",
    "print(f'Logistic (2 features) Accuracy: {acc_2f:.1%}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec1-vis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2)\n",
    "c0, c1 = y_bal==0, y_bal==1\n",
    "\n",
    "axes[0].scatter(f1_raw[c0], f2_raw[c0], c='b', s=10, alpha=0.3, label='Normal')\n",
    "axes[0].scatter(f1_raw[c1], f2_raw[c1], c='r', s=10, alpha=0.3, label='Failure')\n",
    "\n",
    "# 결정 경계\n",
    "if w[2] != 0:\n",
    "    x1_line = np.linspace(f1_raw.min(), f1_raw.max(), 100)\n",
    "    x1n = (x1_line - f1_mean) / f1_std\n",
    "    x2n = -(w[0] + w[1]*x1n) / w[2]\n",
    "    x2_line = x2n * f2_std + f2_mean\n",
    "    axes[0].plot(x1_line, x2_line, 'k--', lw=2)\n",
    "\n",
    "axes[0].set_title(f'Logistic Regression 2F (Acc={acc_2f:.1%})')\n",
    "axes[0].set_xlabel('Rotational speed [rpm]'); axes[0].set_ylabel('Torque [Nm]')\n",
    "axes[0].legend(); axes[0].grid(alpha=0.3)\n",
    "\n",
    "axes[1].plot(loss_hist_2f, 'b-', lw=1.5)\n",
    "axes[1].set_title('BCE Loss'); axes[1].set_xlabel('epoch'); axes[1].grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout(); plt.show()\n",
    "print('\\n-> 선형 결정 경계 하나로는 두 클래스를 잘 분리할 수 없습니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec2-title",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. Logistic Regression — 5 Features\n",
    "\n",
    "변수를 **5개 전체**로 늘려 봅니다.  \n",
    "같은 선형 모델이지만, feature가 많아지면 정확도가 개선됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec2-train",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5 features 전체, 표준화\n",
    "X5_mean = X_bal.mean(axis=0)\n",
    "X5_std  = X_bal.std(axis=0)\n",
    "X5_norm = (X_bal - X5_mean) / X5_std\n",
    "X5 = np.column_stack([np.ones(len(y_bal)), X5_norm])   # (N, 6)\n",
    "\n",
    "w5 = np.zeros(6)\n",
    "rho = 0.01\n",
    "n_epochs = 300\n",
    "\n",
    "loss_hist_5f = []\n",
    "for ep in range(n_epochs):\n",
    "    o = sigmoid(X5 @ w5)\n",
    "    loss = -np.sum(y_bal * np.log(o+1e-15) + (1-y_bal) * np.log(1-o+1e-15))\n",
    "    loss_hist_5f.append(loss)\n",
    "    grad = X5.T @ (o - y_bal)\n",
    "    w5 = w5 - rho * grad\n",
    "\n",
    "pred_5f = (sigmoid(X5 @ w5) >= 0.5).astype(int)\n",
    "acc_5f = np.mean(pred_5f == y_bal)\n",
    "print(f'Logistic (5 features) Accuracy: {acc_5f:.1%}')\n",
    "print(f'\\n  2 features: {acc_2f:.1%} → 5 features: {acc_5f:.1%}  (+{acc_5f-acc_2f:.1%})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec2-vis",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 4))\n",
    "ax.plot(loss_hist_2f, 'b--', lw=1.5, label=f'2 features ({acc_2f:.1%})')\n",
    "ax.plot(loss_hist_5f, 'r-',  lw=1.5, label=f'5 features ({acc_5f:.1%})')\n",
    "ax.set_title('Logistic Regression: 2F vs 5F')\n",
    "ax.set_xlabel('epoch'); ax.set_ylabel('BCE Loss')\n",
    "ax.legend(); ax.grid(alpha=0.3)\n",
    "plt.tight_layout(); plt.show()\n",
    "print('-> Feature를 늘리면 정보량이 증가하여 정확도가 향상됩니다.')\n",
    "print('   하지만 선형 모델의 한계로 ~83% 수준에서 정체됩니다.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sec3-title",
   "metadata": {},
   "source": "---\n# 3. PyTorch MLP — 5 Features\n\n동일한 5개 feature를 **다층 퍼셉트론(MLP)**으로 학습합니다.  \nPractice 10에서 배운 PyTorch `nn.Sequential` + `Adam` 패턴을 사용합니다.\n\n### 모델 구조\n\n```\nInput(5) → Linear(64) → ReLU → Linear(32) → ReLU → Linear(1) → Sigmoid\n```\n\n> **왜 MLP가 더 잘 될까?**  \n> Logistic Regression은 하나의 초평면(hyperplane)으로 분류합니다.  \n> MLP는 은닉층의 **비선형 변환**을 통해 복잡한 결정 경계를 학습할 수 있습니다.  \n> (Practice 10의 XOR 문제에서 확인한 것과 동일한 원리입니다.)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec3-model",
   "metadata": {},
   "outputs": [],
   "source": "# PyTorch 텐서 변환\nX_t = torch.tensor(X5_norm, dtype=torch.float32)   # (N, 5) — 표준화된 5 features\ny_t = torch.tensor(y_bal,   dtype=torch.float32).unsqueeze(1)  # (N, 1)\n\n# MLP 모델 정의\ntorch.manual_seed(42)\nmodel = nn.Sequential(\n    nn.Linear(5, 64),\n    nn.ReLU(),\n    nn.Linear(64, 32),\n    nn.ReLU(),\n    nn.Linear(32, 1)       # logit 출력 (BCEWithLogitsLoss가 sigmoid 적용)\n)\n\ncriterion = nn.BCEWithLogitsLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n\nprint(model)\nn_params = sum(p.numel() for p in model.parameters())\nprint(f'\\nTotal parameters: {n_params}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec3-train",
   "metadata": {},
   "outputs": [],
   "source": "n_epochs = 500\nloss_hist_mlp = []\n\nfor epoch in range(n_epochs):\n    logits = model(X_t)\n    loss = criterion(logits, y_t)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    loss_hist_mlp.append(loss.item())\n    if (epoch + 1) % 100 == 0:\n        with torch.no_grad():\n            pred = (torch.sigmoid(model(X_t)) >= 0.5).int().flatten()\n            acc = (pred == y_t.int().flatten()).float().mean()\n        print(f'Epoch {epoch+1:3d}  Loss: {loss.item():.4f}  Acc: {acc:.1%}')\n\n# 최종 정확도\nwith torch.no_grad():\n    pred_mlp = (torch.sigmoid(model(X_t)) >= 0.5).int().flatten()\n    acc_mlp = (pred_mlp == y_t.int().flatten()).float().mean().item()\n\nprint(f'\\nMLP (5 features) Final Accuracy: {acc_mlp:.1%}')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sec3-vis",
   "metadata": {},
   "outputs": [],
   "source": "fig, axes = plt.subplots(1, 2)\n\n# Loss curve (MLP만 — NumPy logistic은 total loss, PyTorch는 mean loss로 스케일이 다름)\naxes[0].plot(loss_hist_mlp, 'g-', lw=1.5)\naxes[0].set_title('MLP BCE Loss'); axes[0].set_xlabel('epoch'); axes[0].grid(alpha=0.3)\n\n# 정확도 막대 그래프\nmodels = ['Logistic\\n2 feat', 'Logistic\\n5 feat', 'MLP\\n5 feat']\naccs = [acc_2f, acc_5f, acc_mlp]\ncolors = ['#4488cc', '#cc4444', '#44aa44']\nbars = axes[1].bar(models, [a*100 for a in accs], color=colors, edgecolor='k', width=0.5)\nfor bar, acc in zip(bars, accs):\n    axes[1].text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n                 f'{acc:.1%}', ha='center', va='bottom', fontweight='bold')\naxes[1].set_title('Accuracy Comparison'); axes[1].set_ylabel('Accuracy (%)')\naxes[1].set_ylim(0, 105); axes[1].grid(alpha=0.3, axis='y')\n\nplt.tight_layout(); plt.show()"
  },
  {
   "cell_type": "markdown",
   "id": "summary-title",
   "metadata": {},
   "source": "---\n# 요약\n\n| | Logistic (2F) | Logistic (5F) | MLP (5F) |\n|---|---|---|---|\n| **Features** | RPM, Torque | 5개 전체 | 5개 전체 |\n| **Model** | 선형 (NumPy) | 선형 (NumPy) | 비선형 (PyTorch) |\n| **구조** | $\\sigma(\\mathbf{Xw})$ | $\\sigma(\\mathbf{Xw})$ | 5→64→32→1 (ReLU) |\n| **Parameters** | 3 | 6 | ~2,500 |\n| **Accuracy** | ~75% | ~83% | **~96%** |\n\n### 배운 점\n\n1. **Feature 수 증가** → 정보량 증가 → 정확도 향상 (75% → 83%)\n2. **비선형 모델(MLP)** → 복잡한 결정 경계 학습 가능 → 정확도 극적 향상 (83% → 96%)\n3. 실제 산업 데이터는 선형 분리가 어려운 경우가 많아, **MLP 이상의 모델**이 필요합니다\n\n> Practice 06 (Extra)의 Steel Plates 데이터는 2개 feature만으로도 ~91%가 나왔지만,  \n> AI4I 데이터는 고장 패턴이 복잡하여 선형 모델로는 한계가 분명했습니다.  \n> **데이터의 특성에 따라 적절한 모델을 선택하는 것**이 중요합니다."
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}